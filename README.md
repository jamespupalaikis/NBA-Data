# NBA-Data: Intro <img align="right" src="https://static-s.aa-cdn.net/img/amazon/30600000151889/05c429ffa0a860ed80ca04c1a6724faf?v=1" style="width: 20%; height: auto;max-width: 120px;max-height: 100px">
A series of projects using NBA stats scraped from basketballreference.com. Find here the methods used to scrape basketball season and player statistics, as well as the csv files containing said data. I often use this data for experimental, exploratory, and educational projects, as it is a dataset I am familiar with, within a context that I understand well. It can have some problems applying deep learning and regression methods sometimes, as the data can be somewhat sparse along some features, and drifts due to contexts like rule changes, increasing popularity, team expansions, etc. 70 years of professional basketball is a lot of data for a human, but for data-hungry ML models it can often be woefully inadequate

## The Data: <img align="right" src="https://officialpsds.com/imageview/75/xz/75xzxq_large.png?1521316543" style="width: 10%; height: auto;max-width: 120px;max-height: 100px">
The "nbadata" folder contains all of the stat tables utilized by the various projects in this repository. Additionally, it has all of the programs (albeit in a very raw form) that were used to scrape and save the data. All of the data was scraped from basketballreference.com, who I am very grateful to for making their data public, clean, and scrapable. The process was done through a combination of the beautifulsoup python module, and the aptly basketball_reference_scraper for some more advanced player height data. Processing and organizing of the data was all done through numpy and pandas. Though there are other ways to obtain NBA statistics, this was a very enjoyable experience for me. I was able to package and manipulate the data as I pleased, it was free, and best of all I got practice refining and polishing my knowledge of Pandas in the process. 
## NBA-KMeans:  <img align="right" src="https://interactives.dallasnews.com/2019/every-shot-dirk-ever-took/images/_dirk-hero.png" style="width: 13%; height: auto;max-width: 120px;max-height: 100px">
This is an EDA-style project focused primarily around K-Means clustering algorithm. Media surrounding the NBA has recently introduced the idea of "unicorns": players with skillsets commonly associated with shorter "guard" position players, who nonetheless tower at the gargantuan heights of the tallest NBA giants. I set out to attempt to cluster NBA players by their contributions by using the K-Means algorithm on profiles of their box score statistics, in order to identify some more of these unicorns from a statistical point of view. Upon clustering, I then went about contextually analyzing each cluster. First, I looked at the players contained in each cluster and made a preliminary hypothesis of how players were segmented on a subjective basis. I then explored this hypthesis by plotting the data along different axes, visualizing the clusters on different types of plots, and projecting it onto its two main dimensions according to the T-SNE dimensionality reduction algorithm. I ended up with very satisfying results that I am quite pleased with!

## PyTorch-NBA-Predict: <img align="right" src="https://www.nba.com/stats/media/players/700/203954.png" style="width: 20%; height: auto;max-width: 120px;max-height: 100px">
This was a short project that I completed with the goal of better familiarizing myself with the ins and outs of model creation and data loading in PyTorch. For a long time, I only used TensorFlow for all deep learning applications, as it was the deep learning tool I was most comfortable and experienced with. However, with 2022 fast approaching I decided it was finally time to address this, and after a few cookie-cutter examples, wanted to create an unguided PyTorch project. This model aims to predict the likelihood of a player making an NBA all-star team (or can be simply adjusted to instead predict any other accolade) based on the statistics of their rookie season. Due to the above mentioned limitations of the dataset, combined with the enormity of the problem being solved (If anyone actually had a model that could consistently predict this they would be unfathomably rich), the model did not work very well, but it served as a great lesson in using PyTorch. I actually think that I prefer Torch to Tensorflow/Keras at this point in time, and for that reson, I definitely consider this project a success. (NOTE: this program currently needs a bit of love and care. It needs to be cleaned, organized, and onfigured to properly store/graph model metrics. I am working on a big exciting project currently that is taking up all of my time but It will be done soon! Keep Posted!)
