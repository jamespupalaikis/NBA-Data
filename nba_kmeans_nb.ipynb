{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who are the NBA's *biggest* unicorns?\n",
    "\n",
    "### -Background\n",
    "Ever since Lithuanian player Kristaps Porzingis was described by fellow big man Kevin Durant as a \"unicorn\" for his uncanny ability to shoot long shots despite his enormous 7'3\" stature, the term has proliferated across basketball circles to describe players who are abnormally skilled at shooting (a skill that has become increasingly coveted in the modern NBA) while fielding the staggering height that has long been a trademark of the league. The term has since colloquially expanded to refer to players with a combination of height and skills that have rarely been seen before in the NBA\n",
    "\n",
    "### -The Project\n",
    "The increased interest in a \"positionless\" basketball where all players possess a full range of basketball skills in tandem with gargantuan height got me interested in what sorts of archetypes exist among players, and who the biggest outliers of these grouping are with respect to height. Being a short guy myself, I am also keenly interested in short players who encapsulated typically \"big man\" roles despite their stature as well, so I will be investigating both sides of this height spectrum.\n",
    "\n",
    "### - Approach\n",
    "I plan to use K-Means clustering to group NBA players in my dataset (scraped from basketballreference.com) based on their stat averages in their prime in an unsupervised way. Clustering will be done on the following stat dimensions: \n",
    "*3 Point attempts, 3 point percentage, 2 point attempts, 2 point percentage, Free throw attempts, Free throw percentage, Offensive rebounds, Defensive rebounds, Assists, Steals, Blocks, Turnovers, and of course, Points.* These statistics will be given as average per-season totals over at most 5 years (though if the player has played fewer than 5 total seasons, all seasons will simply be averaged together. These clusters will then be observed for coherence, and I will then isolate the shortest and tallest players in each cluster, as well as try to assign a basketball context to each cluster. Notice how height was not one of the clustering dimensions, as I hope to try to capture groupings outside of the natural position system in basketball, and focus more on the skillsets of the players instead. \n",
    "\n",
    "### - Some notes on the methods\n",
    "I had to make several judgement calls on the methods in this project, which I would like to address and justify a few: \n",
    "\n",
    "- I spent a long time agonizing over the best way to define the \"prime\" of a player statistically. While players like LeBron James and Kareem Abdul-Jabbar have had their careers defined by consistent excellence over multiple decades, this is not the sort of \"role\" that I want to isolate. I instead am more interested in the role a player fills within their team at a given time, for however long that is. I therefore chose to choose the 5 year stretch in a player's career that had the most cumulative minutes played, as I wanted to isolate the period where they had the most impact on the court and therefore hopefully gave the most statistically significant contributions to their specific on court role. \n",
    "- I included both shot attempts and percentage in the clustering dimensions (e.g. 3 point attempts and 3 point percentage), as opposed to sever other options, for example, just including total shots made for the season, which at first glance, appears to capture most of the information in the previous 2 metrics. This is because in basketball, and especially \"positionless basketball\", there is an increasingly large focus on the concept of \"scalability\". That is, the ability for a player to maintain their scoring efficiency when given a larger role on the team, i.e. more shot attempts. This is something I wanted recognized in my clusters, so I chose to include both in my data.\n",
    "- In a similar vein, I included both offensive and defensive rebounds as opposed to simply total rebounds in my data. Offensive rebounds are generally considered to be more valuable than defensive rebounds, and the prototypical \"defensive juggernaut\" in basketball typically racks up tons of offensive rebounds. I included defensive rebounds as well to add more of a weighting to on court roles that occupy the paint more, but stopped short of also including total rebounds, as it is obviously fully correlated with ORBs and DRBs. \n",
    "- I ended up using average season totals instead of per-game averages because it gave far more sensible results. I am not sure exactly why, and hope to investigate further. I refrained from inluding games played, games started, or minutes played (which reasonably would normalize the data for players who frequently got injured), because when this data was included, there was a sharp dichotomy created between bench players and starters wherein the k-means algorithm would always suggest only 2 clusters with these two groups due to the vast difference in statistics between them. This effect is still present in the clusters, as we will see, but in a much more muted and reasonable way. Additionally, I also made a cutoff of 1500 minutes played in a season (on average) to be included in the data, for the same reason; there was too sharp of a dichotomy between players that actually played and those that simply occupied the bench for nearly all of the season. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG',\n",
      "       'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT',\n",
      "       'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'Year', 'MVP', 'DPOY', 'AllNBA', 'AllDef', 'Playoffs', 'FMVP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "seasons = pd.read_csv('nbadata/seasondata.csv')\n",
    "p = pd.read_csv('nbadata/playerdata.csv')\n",
    "\n",
    "#make the cutoff at 1980 when all of the relevant stats were first recorded\n",
    "seasons = seasons.loc[seasons['Year'] >= 1980]\n",
    "players = pd.unique(seasons['Player'])#list of players for our dataset\n",
    "print(seasons.columns)\n",
    "#Now to create a DF of the average stats from the player's 5 consecutive seasons with the most minutes played\n",
    "data = pd.DataFrame(players,columns = ['Player'])\n",
    "data['Yr'] = 0 #first year of 5yr average\n",
    "data['Height'] = 0 #These first few stats are recorded for later observation of the clusters\n",
    "data['GS'] = 0\n",
    "data['MP'] = 0\n",
    "data['3P'] = 0\n",
    "data['3P%'] = 0\n",
    "data['2P'] = 0\n",
    "data['2P%'] = 0\n",
    "data['FTA'] = 0\n",
    "data['FT%'] = 0\n",
    "data['ORB'] = 0\n",
    "data['DRB'] = 0\n",
    "data['AST'] = 0\n",
    "data['STL'] = 0\n",
    "data['BLK'] = 0\n",
    "data['TOV'] = 0\n",
    "data['PTS'] = 0\n",
    "\n",
    "\n",
    "stattomax = 'MP'#maximize minutes played over 5 year span\n",
    "for guy in players:\n",
    "    #print(guy)\n",
    "    playerind = data.loc[data['Player'] == guy]\n",
    "    pi = playerind.index #grab the index of the player's spot in our data df\n",
    "    ph = p.loc[p['Player'] == guy]['Height'].values #grab their height from our player data df\n",
    " \n",
    "    stats = seasons.loc[seasons['Player'] == guy] #grab all of their seasons played from seasons df (up to 2020)\n",
    "    \n",
    "    #now to find each player's \"prime\"\n",
    "    runs = stats.count()['Player'] - 4\n",
    "    startage = stats['Age'].to_list()[0]\n",
    "    firstyr = stats['Year'].to_list()[0]\n",
    "    if(runs < 0):\n",
    "        av = stats.mean()\n",
    "        y = firstyr\n",
    "    else:\n",
    "        max = [startage,0]\n",
    "        for i in range(runs):\n",
    "            check = stats.loc[stats['Age'] >= startage + i].loc[stats['Age'] < startage + i + 5].sum()\n",
    "            if(check[stattomax] > max[1]):\n",
    "                max[0] = startage + i\n",
    "                max[1] = check[stattomax]\n",
    "                y = firstyr + i\n",
    "        av = stats.loc[stats['Age'] >= max[0]].loc[stats['Age'] < max[0] + 5].mean()\n",
    "\n",
    "        \n",
    "    data._set_value(pi, 'Yr', y)\n",
    "    if(ph.size > 0): #only include player height data that we could actually scrape\n",
    "        data._set_value(pi, 'Height', ph)\n",
    "    for col in data.columns[3:]:\n",
    "        data._set_value(pi, col, av[col])\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#data= data.dropna()\n",
    "\n",
    "\n",
    "data=data.loc[data['MP'] >= 1500].loc[data['GS'] >= 41]\n",
    "\n",
    "\n",
    "npdata = data.drop(columns= ['Player', 'Yr','GS', 'MP', 'Height']).to_numpy()\n",
    "#now drop the unused columns and get ready to cluster the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First to normalize the data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sdata = scaler.fit_transform(npdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial clustering, to determine the optimal number of groupings\n",
    "\n",
    "kmeans_kwargs = {\"init\": \"random\",\"n_init\": 10,\"max_iter\": 300,\"random_state\": 42,}\n",
    "sse = []\n",
    "for k in range(1, 23):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(sdata)\n",
    "    sse.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the kneed python module to find the knee point in the number of groups based on SSE\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 23), sse)\n",
    "plt.xticks(range(1, 23))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "kl = KneeLocator(\n",
    "range(1, 23), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "print(kl.elbow)\n",
    "clusternum = kl.elbow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have determined the best number of groups is 5, so lets append our \"data\" df with each player's\n",
    "#cluster and their euclidean distance from the centroid\n",
    "\n",
    "kmeans = KMeans(init=\"random\",n_clusters=clusternum,n_init=20,max_iter=300,random_state=42)#5,20\n",
    "kmeans.fit(sdata)\n",
    "print(kmeans.n_iter_, \" iterations to complete\")\n",
    "distances = []\n",
    "for i in range(len(sdata)): #find euclidean distance from respective cluster center\n",
    "    cluster = kmeans.cluster_centers_[kmeans.labels_[i]]\n",
    "    dist = np.linalg.norm(sdata[i] - cluster)\n",
    "    distances.append(dist)\n",
    "data['Cluster'] =  kmeans.labels_\n",
    "data['Distance'] = distances\n",
    "#print(data)\n",
    "data.to_csv('best5yraverage.csv') #save the data to more easily parse and examine it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster analysis\n",
    "\n",
    "I ended up messing around with some different hyperparameters, and ended up with the process that you see above. The results were better than I expected, with some pretty clear roles being defined. So let's get into it!\n",
    "\n",
    "### Cluster 4: The Paint Protectors\n",
    "<br>**Analysis**  These players are not exactly backups (we avoided that by filtering by minutes/games played) but they are notable for their lack of scoring and high paint presence. It is obvious that in this cluster the algorithm isolated a group of players that performs well in getting rebounds and blocks, with a generally high 2 point percentage from getting dunks at the rim. While there are some great players here, like Rudy Gobert, Ben Wallace, Dennis Rodman, and Marc Gasol, the k-means algorithm seems stubborn to classify them here due to their lack of star level scoring output. \n",
    "<br>**Notable Players** Marc Gasol, Tristan Thompson, Udonis Haslem, Tyson Chandler, Marcus Camby, Brook Lopez, Hassan Whiteside, Serge Ibaka, Clint Capela, Rudy Gobert, Ben Wallace, DeAndre Jordan, Steven Adams\n",
    "<br>**Notable Outliers** *Honestly I'm not claiming to have an extensive knowledge of historical mid-level big men, but this group does seem to be fairly consistent, with no huge outliers that I can pick out* \n",
    "\n",
    "\n",
    "### Cluster 3: The Heliocentric Star\n",
    "<br>**Analysis**  This group can be best understood by the player closest to the centroid of the cluster: Russel Westbrook. This cluster consists of \"system superstars\". These players act as the focal point of their team in almost every way, with absurdly high attempt numbers in all categories, extreme scoring, and most distinguishingly, incredibly passing numbers. Any non-center face of the league can be found in this cluster. Interestingly, the furthest player from the centroid is **the** Michael Jeffrey Jordan, who likely sits so far from everyone due to his out-of-this-world scoring, even amongst his hall of fame peers in this group. This is the smallest cluster, an elite club infiltrated only by finals MVP Andre Iguodala...\n",
    "<br>**Notable Players** Magic Johnson, Larry Bird, Stephen Curry,James Harden, LeBron James, Michael Jordan, Scotty Pippen, Chris Paul, Trae Young, Luka Doncic, Kobe Bryant, Allen Iverson, Dwyane Wade, Kevin Durant, Carmelo Anthony, and more...\n",
    "<br>**Notable Outliers** Andre Iguodala\n",
    "\n",
    "### Cluster 2: The \"3 and D\"\n",
    "<br>**Analysis**  Ah, the 3 and D... A staple of modern basketball team construction, as general managers have wisened up to the realities of the NBA game as played today, the value of players who can recieve outlet passes from their cluster 3 superstars, shoot  pointers well enough to space the floor, and not get destroyed on defense has skyrocketed. This group features plenty of familiar names from the \"original 3 and D guy\" Shane Battier, to current NBA lineup stalwarts like George Hill, Duncan Robinson, Marcus Morris, and Avery Bradley. \n",
    "<br>**Notable Players**George Hill, Robert Horry, Raja Bell, Shane Battier, Kentavious Caldwell-Pope, PJ Tucker, Bojan Bogdanovich, Danny Green\n",
    "<br>**Notable Outliers** D'Angelo Russel, Zach LaVine, Brandon Ingram\n",
    "\n",
    "### Cluster 1: The Giants among Men\n",
    "<br>**Analysis**  This cluster houses the league's best and biggest. Homing in on even more of the paint stats accrued by cluster 4, supercharged with extreme scoring numbers, the likes of Tim Duncan, Shaquille O'Neal, Kevin Garnett, and Hakeem Olajuwon can be found in this group. To my chagrin, the group seems focused on mostly scoring and paint stats, which unfortunately funnels in some \"unicorn\" big men like the passing savant Nikola Jokic and sharpshooting Karl Anthony-Towns. That being said, the star big men throughout the league's history seem to be accurately parsed and selected for this cluster. \n",
    "<br>**Notable Players** Hakeem Olajuwon, Anthony Davis, Pau Gasol, Dwight Howard, Joel Embiid, Andrei Kirilenko, Drik Nowitski \n",
    "<br>**Notable Outliers** Lamar Odom, Delef Schrempf, Zydrunas Ilgauskas (This is the best cluster for cool names, in case you didnt notice)\n",
    "\n",
    "### Cluster 0: The \"In-Betweeners\"\n",
    "**Analysis**  Finally we reach the last and most confounding cluster identified. This group seems to be an amalgamation of two different groups of players, and notably contains a few players that one would expect to fall into other groups already identified. The main connecting threads that I could find amongst the players in this cluster were \n",
    "1. Slashing shooting guards and point guards who did not shoot many 3 pointers, and gained most of their on court value driving to the rim and passing. \n",
    "2. pass first point guards with relatively low scoring output, such as Rajon Rondo or Draymond Green\n",
    "Overall, it seems that this cluster gained many of of the \"in between\" non-big superstars who do not quite fall into cluster 3, but are still the focal point of their team. Notable exceptions include some excellent shooters such as Ray Allen, Klay Thompson, and Kyrie Irving, as well as some true superstars like Damian Lillard, Kawhi Leonard, and Steve Nash. \n",
    "<br>**Notable Players** Victor Oladipo, Shai Gilges-Alexander, De'Aaron Fox, Jimmy Butler, Ja Morant, Kyle Lowry, Steve Nash, Draymond Green, Rajon Rondo, Donovan Mitchell\n",
    "<br>**Notable Outliers** Kyrie irving, Goran Dragic, Khris Middleton, Jamal Murray, Bradley Beal, Kawhi Leonard, Damian Lillard, Ray Allen, Kevin Love, Klay Thompson, CJ McCollum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to isolate metrics from each cluster: \n",
    "groups = []\n",
    "for i in range(5):\n",
    "    groups.append(data.drop(columns = ['Yr', 'Player', 'Cluster']).loc[data['Cluster'] == i].median())\n",
    "    print('Data for group number: ', i)\n",
    "    print(groups[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data fit well with what we would expect from the groups described. Obviously the center groups average a greater height, as well as more of the stats commonly associated with height: Rebounds, blocks, and 2 point percentage (since dunks have a far higher percentage on average). The starter/star player archetypes obviously average more minutes played and games started, as well as far more points. Overall the data are somewhat hard to parse, so let's put this into a nicer visualization using one of my favorite plot types: radar plots, or spider plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from sklearn import preprocessing\n",
    "\n",
    "stats = data\n",
    "df = stats.loc[stats['Player'] == '']\n",
    "cols = stats.columns[1:]\n",
    "groups = []\n",
    "for i in range(5):\n",
    "    groups.append((stats.loc[stats['Cluster'] == i]).mean().to_numpy())\n",
    "\n",
    "groups = np.array(groups)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "sgroups = min_max_scaler.fit_transform(groups)\n",
    "sgroups += 0.2\n",
    "\n",
    "df = pd.DataFrame(data = sgroups, columns= cols).drop(columns=['Yr', 'Cluster', 'Distance', 'Height'])\n",
    "\n",
    "\n",
    "\n",
    "def make_spider(row, title, color):\n",
    "    # number of variable\n",
    "    categories = list(df)#[1:]\n",
    "    N = len(categories)\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2, 6, 2 * row + 1, polar=True, )\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=6)\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0, .25, .5, .75], [\" \", \" \", \" \", \" \"], color=\"grey\", size=7)\n",
    "    plt.ylim(0, 1)\n",
    "    # Ind1\n",
    "    values = df.loc[row].drop(columns = ['Year']).values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=1, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=11, color=color, y=1.5)\n",
    "\n",
    "    my_dpi = 96\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    "\n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider(row=row, title=row, color=my_palette(row))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualizes what I described before much more nicely. Stats are depicted as the radius of the plot, so it is important to pay no mind to the area of the plots themselves, but instead focus on the radius at each metric instead.  Note that the stats have been normalized so a stat with a radius of zero is simply the lowest value among the five clusters, and says nothing about the absolute value of the stat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a more in depth look at how the clusters look, and how exactly they were separated by the K means algorithm. We have far too many dimensions to visualize all at once, so I will start by showing some scatter plots with different pairings of axis dimensions, and then use dimensionality reduction to try and visualize the entire clusters at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(enumerate(stats['Player']))\n",
    "print(stats)\n",
    "\n",
    "a0 = stats.loc[stats['Cluster'] == 0]\n",
    "a1 = stats.loc[stats['Cluster'] == 1]\n",
    "a2 = stats.loc[stats['Cluster'] == 2]\n",
    "a3 = stats.loc[stats['Cluster'] == 3]\n",
    "a4 = stats.loc[stats['Cluster'] == 4]\n",
    "######################################################\n",
    "playerstolabel = ['Hakeem Olajuwon', \"Shaquille O'Neal\"]\n",
    "\n",
    "x0,y0 = (a0['PTS']), (a0['ORB'] + a0['DRB'])#.to_numpy()\n",
    "x1,y1 = (a1['PTS']), (a1['ORB'] + a1['DRB'])#.to_numpy()\n",
    "x2,y2 = (a2['PTS']), (a2['ORB'] + a2['DRB'])#.to_numpy()\n",
    "x3,y3 = (a3['PTS']), (a3['ORB'] + a3['DRB'])#.to_numpy()\n",
    "x4,y4 = (a4['PTS']), (a4['ORB'] + a4['DRB'])#.to_numpy()\n",
    "print(len(x0), len(y0))\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "\n",
    "ax1.scatter(x0,y0, s=10, c='b', marker=\"s\", label='0')\n",
    "ax1.scatter(x1,y1, s=10, c='g', marker=\"s\", label='1')\n",
    "ax1.scatter(x2,y2, s=10, c='r', marker=\"s\", label='2')\n",
    "ax1.scatter(x3,y3, s=10, c='c', marker=\"s\", label='3')\n",
    "ax1.scatter(x4,y4, s=10, c='m', marker=\"s\", label='4')\n",
    "\n",
    "plt.title('Points vs. Rebounds')\n",
    "ax1.legend(loc='upper left');\n",
    "'''for guy in names:\n",
    "    if(guy[1] in playerstolabel):# or (clustrs[guy[0]] == 'g'):\n",
    "        print(guy)\n",
    "        print(type(x0), type(y0))\n",
    "        ax1.annotate(guy[1],( x0.iloc[guy[0]], y0.iloc[guy[0]]))'''\n",
    "plt.show()\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "x00,y00 = a0['PTS'], a0['AST']\n",
    "x01,y01 = a1['PTS'], a1['AST']\n",
    "x02,y02 = a2['PTS'], a2['AST']\n",
    "x03,y03 = a3['PTS'], a3['AST']\n",
    "x04,y04 = a4['PTS'], a4['AST']\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax01 = fig2.add_subplot()\n",
    "\n",
    "ax01.scatter(x00,y00, s=10, c='b', marker=\"s\", label='0')\n",
    "ax01.scatter(x01,y01, s=10, c='g', marker=\"s\", label='1')\n",
    "ax01.scatter(x02,y02, s=10, c='r', marker=\"s\", label='2')\n",
    "ax01.scatter(x03,y03, s=10, c='c', marker=\"s\", label='3')\n",
    "ax01.scatter(x04,y04, s=10, c='m', marker=\"s\", label='4')\n",
    "plt.title('Points vs. Assists')\n",
    "ax01.legend(loc='upper left');\n",
    "plt.show()\n",
    "\n",
    "#################################################33\n",
    "\n",
    "x000,y000 = a0['3P'], a0['2P']\n",
    "x001,y001 = a1['3P'], a1['2P']\n",
    "x002,y002 = a2['3P'], a2['2P']\n",
    "x003,y003 = a3['3P'], a3['2P']\n",
    "x004,y004 = a4['3P'], a4['2P']\n",
    "\n",
    "fig3 = plt.figure()\n",
    "ax001 = fig3.add_subplot()\n",
    "\n",
    "ax001.scatter(x000,y000, s=10, c='b', marker=\"s\", label='0')\n",
    "ax001.scatter(x001,y001, s=10, c='g', marker=\"s\", label='1')\n",
    "ax001.scatter(x002,y002, s=10, c='r', marker=\"s\", label='2')\n",
    "ax001.scatter(x003,y003, s=10, c='c', marker=\"s\", label='3')\n",
    "ax001.scatter(x004,y004, s=10, c='m', marker=\"s\", label='4')\n",
    "plt.title('3P vs. 2P')\n",
    "ax01.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "playerstolabel = ['Kareem Abdul-Jabbar', 'Dennis Rodman', 'Michael Jordan', 'Tayshaun Prince','Eddy Curry', \n",
    "                 'Joel Embiid', 'Ben Simmons', 'Andrei Kirilenko','Luka Dončić', 'Trae Young', 'Jimmy Butler']\n",
    "clustrs = data['Cluster']\n",
    "def clustercolors(c):\n",
    "    if(c == 0):\n",
    "        return 'b'\n",
    "    elif(c == 1):\n",
    "        return 'g'\n",
    "    elif(c == 2):\n",
    "        return 'r'\n",
    "    elif(c == 3):\n",
    "        return 'c'\n",
    "    elif (c == 4):\n",
    "        return 'm'\n",
    "    else: \n",
    "        return 'k'\n",
    "\n",
    "clustrs = clustrs.apply(clustercolors).to_list()\n",
    "print(len(clustrs))\n",
    "stats1 = data.drop(columns = ['Player'])\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1,learning_rate = 35 ,perplexity=25, n_iter=2000,random_state = 100)#,init = 'pca')\n",
    "tsne_results = tsne.fit_transform(stats1)\n",
    "\n",
    "tsne_results\n",
    "xx,yy = (list(zip(*tsne_results)))\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xx,yy, c = clustrs)\n",
    "bpatch = mpatches.Patch(color='blue', label='0')\n",
    "gpatch = mpatches.Patch(color='green', label='1')\n",
    "rpatch = mpatches.Patch(color='red', label='2')\n",
    "cpatch = mpatches.Patch(color='cyan', label='3')\n",
    "mpatch = mpatches.Patch(color='magenta', label='4')\n",
    "ax.legend(handles=[bpatch, gpatch, rpatch, cpatch, mpatch])\n",
    "for guy in names:\n",
    "    if(guy[1] in playerstolabel):# or (clustrs[guy[0]] == 'g'):\n",
    "        ax.annotate(guy[1],( xx[guy[0]], yy[guy[0]]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here that with T-SNE Clustering instead, we get groupings fairly consistent with the K-means results. Some obvious outliers include some of the NBA's most peculiar players; the likes of Joel Embiid, Dennis Rodman, Andrei Kirilenko, and Ben Simmons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data.loc[data[\"Height\"] != 0]\n",
    "for i in range(5):\n",
    "    guys = data1.loc[data1['Cluster'] == i]\n",
    "    biggest = (guys.loc[guys['Height'].idxmax()])\n",
    "    smallest = (guys.loc[guys['Height'].idxmin()])\n",
    "    print(f\"cluster {i}'s biggest player: {biggest['Player']}\")\n",
    "    print(f\"cluster {i}'s smallest player: {smallest['Player']}\")\n",
    "    #print(smallest['Player'], 'small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's it! we can see it was moderately successful, with some of our unicorns being historical height outliers. Players such as \"the best pound for pound player\", \"the answer\" Allen Iverson, Big man superstart Tom Chambers, as well as our original unicorn Kristaps Prozingis! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
